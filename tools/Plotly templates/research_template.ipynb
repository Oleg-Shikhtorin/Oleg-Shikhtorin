{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.io as pio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import performance_metrics, cross_validation\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "import itertools\n",
    "import holidays\n",
    "\n",
    "sys.path.append('../../src')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_client = bigquery.Client(project='analytics-dev-333113', location = 'europe-north1')\n",
    "\n",
    "output_path = '../../../../..////' # path\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cache_path = 'cache_dir'\n",
    "cache_dir = Path(cache_path)\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.templates.default = 'plotly_white'\n",
    "pio.templates['plotly_white_custom'] = pio.templates['plotly_white']\n",
    "pio.templates['plotly_white_custom']['layout']['xaxis'].update(showline=True, linecolor='black', tickfont=dict(size=10)) #, zeroline=True, zerolinecolor='black')\n",
    "pio.templates['plotly_white_custom']['layout']['yaxis'].update(showline=True, linecolor='black', tickfont=dict(size=10))\n",
    "\n",
    "pio.templates.default = 'plotly_white_custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_list = [1234,]\n",
    "\n",
    "scheduler_dict = {\n",
    "    1234:{\n",
    "        'start_dt':'2026-01-01',\n",
    "        'daily':{2:[(7,8),(17,18)],3:[(7,8),(17,18)],4:[(7,8),(17,18)],5:[(7,8),(17,18)],6:[(7,8),(17,18)],7:[(12,23)],1:[(12,23)]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_to_avg(df: pd.DataFrame, metric_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces outliers in metrics with the average value of the previous and next day\n",
    "    metric_cols: List of column names with metrics where outliers need to be replaced\n",
    "    Returns: pandas.DataFrame with outliers replaced\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    for metric_col in metric_cols:\n",
    "        Q1 = df[metric_col].quantile(0.25)\n",
    "        Q3 = df[metric_col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        is_outlier = (df[metric_col] < lower_bound) | (df[metric_col] > upper_bound)\n",
    "\n",
    "        for idx in df[is_outlier].index:\n",
    "            if 0 < idx < len(df) - 1:\n",
    "                prev_value = df.loc[idx - 1, metric_col]\n",
    "                next_value = df.loc[idx + 1, metric_col]\n",
    "                avg_value = np.mean([prev_value, next_value])\n",
    "                df.loc[idx, metric_col] = avg_value\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avg(df: pd.DataFrame, metric_cols: list[str], n_lag: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies a rolling average to specified columns of a DataFrame\n",
    "    n_lag (int): Window size for the rolling average\n",
    "    Returns: pandas.DataFrame with specified columns replaced by their rolling averages\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in metric_cols:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].rolling(window=n_lag, min_periods=1).mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yoy_ratio(data: pd.DataFrame, metric_cols: list[str], metric_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    data: pandas.DataFrame with columns 'dt_part' and specified in metric_cols columns of a DataFrame\n",
    "    metric_type: absolute ('abs') or relative ('rel')\n",
    "    Returns: pandas.DataFrame, copy of original one with column 'yoy_ratio'\n",
    "    \"\"\"\n",
    "    cols = ['dt_part'] + metric_cols\n",
    "    df  = data[cols].sort_values('dt_part').copy()\n",
    "    df['dt_part'] = df['dt_part'].dt.tz_localize(None)\n",
    "    cur_year = df['dt_part'].dt.year.max()\n",
    "    prev_year = cur_year-1\n",
    "\n",
    "    df = pd.concat([\n",
    "        df[df['dt_part'].dt.year == cur_year].reset_index(drop=True),\n",
    "        df[df['dt_part'].dt.year == prev_year].reset_index(drop=True).rename(columns=dict(zip(cols,[_+'_lag' for _ in cols]))),\n",
    "    ], axis=1).dropna()\n",
    "\n",
    "    if metric_type == 'abs':\n",
    "        for col in metric_cols:\n",
    "            df[f'{col}_yoy'] = df[col] / df[f'{col}_lag'] -1\n",
    "    elif metric_type == 'rel':\n",
    "        for col in metric_cols:\n",
    "            df[f'{col}_yoy'] = df[col] - df[f'{col}_lag']\n",
    "    else:\n",
    "        raise ValueError(f\"metric_type has to be one of the following: 'abs' for absolute values or 'rel' for relative ones\")\n",
    "\n",
    "    df = df[['dt_part','dt_part_lag']+metric_cols+[_+'_lag' for _ in metric_cols]+[_+'_yoy' for _ in metric_cols]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_dict(city_ids_list: list[int]) -> dict[int, dict]:\n",
    "    \"\"\"\n",
    "    Returns a dict of format:\n",
    "    {City ID: {\n",
    "        'city_name': City name, \n",
    "        'country_id': Country ID, \n",
    "        'country_name': Country name}\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    if not city_ids_list:\n",
    "        raise ValueError('Empty list found')\n",
    "    elif not all(isinstance(_, int) for _ in city_ids_list):\n",
    "        raise TypeError('The list of cities IDs must contain only integers')\n",
    "    geo_query = f\"SELECT country_id, country_name, city_id, city_name FROM `indriver-e6e40.heap.vw_geo_mapping` WHERE city_id IN {tuple(city_ids_list)}\"\n",
    "    geo_dict = {row[2]:{'city_name':row[3], 'country_id':row[0], 'country_name':row[1]} for row in bigquery_client.query(geo_query)}\n",
    "    return geo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vrect(city_id:int, max_dt:str, figure:go._figure.Figure, scheduler_dict:dict):\n",
    "    daynum_mapping = dict(zip(\n",
    "        range(0,7),\n",
    "        [_ + 2 if _ != 6 else 1 for _ in range(0,7)]\n",
    "    ))\n",
    "    start_dt = datetime.strptime(scheduler_dict[city_id]['start_dt'], '%Y-%m-%d')\n",
    "    end_dt = datetime.strptime(max_dt, '%Y-%m-%d')\n",
    "    current_dt = start_dt\n",
    "\n",
    "    while current_dt <= end_dt:\n",
    "        day_of_week = daynum_mapping[current_dt.weekday()]\n",
    "        if day_of_week in scheduler_dict[city_id]['daily']:\n",
    "            for start_time, end_time in scheduler_dict[city_id]['daily'][day_of_week]:\n",
    "                start_dttm = datetime.combine(current_dt, datetime.min.time()) + timedelta(hours=start_time)\n",
    "                end_dttm = datetime.combine(current_dt, datetime.min.time()) + timedelta(hours=end_time+1)\n",
    "                figure.add_vrect(x0=start_dttm, x1=end_dttm, line_width=0, fillcolor='blue', opacity=.05)\n",
    "        current_dt += timedelta(days=1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hours(data:pd.DataFrame, city_id:int, max_dt:str, scheduler_dict:dict):\n",
    "    df = data.copy()\n",
    "    start_dt = scheduler_dict[city_id]['start_dt']\n",
    "    city_schedule = scheduler_dict[city_id]['daily']\n",
    "\n",
    "    def is_within_schedule(row):\n",
    "        day, hour = row['weekday'], row['hour']\n",
    "\n",
    "        if day not in city_schedule:\n",
    "            return False\n",
    "        for start, end in city_schedule[day]:\n",
    "            if start <= hour <= end:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    df = df[\n",
    "        (df['city_id'] == city_id) &\n",
    "        (df['dt_part'] <= max_dt) &\n",
    "        df.apply(is_within_schedule, axis=1)\n",
    "    ]\n",
    "    return df.sort_values('dt_part').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonality_data(data: pd.DataFrame, metric_cols: list[str], scale:bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    data: pandas.DataFrame with columns 'dt_part' and specified in metric_cols columns of a DataFrame\n",
    "    Returns: pandas.DataFrame, copy of original one with column 'yoy_ratio'\n",
    "    \"\"\"\n",
    "    cols = ['dt_part','year'] + metric_cols\n",
    "    df  = data[cols].sort_values('dt_part').copy()\n",
    "    df['dt_part'] = df['dt_part'].dt.tz_localize(None)\n",
    "    years = sorted(df['year'].unique())[::-1]\n",
    "    last_year = years[0]\n",
    "    first_year = years[-1]\n",
    "\n",
    "    res = df[df['year'] == last_year].reset_index(drop=True)\n",
    "    datapoints = res.shape[0]\n",
    "    current_year = last_year-1\n",
    "\n",
    "    # scaling\n",
    "    if scale:\n",
    "        for col in metric_cols:\n",
    "            res[col] = (res[col] - res[col].mean()) / res[col].mean()\n",
    "\n",
    "    while current_year >= first_year:\n",
    "        temp_df = df[df['year'] == current_year].reset_index(drop=True)[:datapoints]\n",
    "        temp_df['dt_part'] = res[res['year'] == last_year]['dt_part'].values\n",
    "        if scale:\n",
    "            for col in metric_cols:\n",
    "                temp_df[col] = (temp_df[col] - temp_df[col].mean()) / temp_df[col].mean()\n",
    "        res = pd.concat([\n",
    "            res,\n",
    "            temp_df\n",
    "        ], axis =0) # long\n",
    "        current_year -= 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(df):\n",
    "    # Продлим линии доверительного интервала и прогноза до конца факта, чтоб они красиво сошлись в одной точке\n",
    "    df = df.copy().sort_index()\n",
    "    last_fact_date = df.forecast.dropna().index[0] - pd.DateOffset(1)\n",
    "    df.loc[last_fact_date, ['forecast', 'low', 'high']] = df.loc[last_fact_date, 'value']\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Fact line\n",
    "    fig.add_scatter(x=df.index, y=df.value, name='fact')\n",
    "    # Confidence interval\n",
    "    fig.add_traces([\n",
    "        go.Scatter(x = df.index, y=df.high, mode = 'lines',line_color = 'rgba(0,0,0,0)', showlegend = False),\n",
    "        go.Scatter(x = df.index, y=df.low, mode = 'lines', line_color = 'rgba(0,0,0,0)', name = 'confidence interval', fill='tonexty', fillcolor = 'rgba(150, 150, 150, 0.5)')\n",
    "    ])\n",
    "    # Forecast line\n",
    "    fig.add_scatter(x=df.index, y=df.forecast, name='forecast')\n",
    "    \n",
    "    # Last fact date used for forecast calculation\n",
    "    fig.add_vline(x=last_fact_date, line_width=1, line_dash='dash', line_color='black')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_filter_and_markup(data: pd.DataFrame, city_id:int, scheduler_dict:dict, metric_nm:str) -> pd.DataFrame:\n",
    "    df = data[data['dt_part'].dt.date < datetime(2025,3,3).date()][['dt_part','year','weekday','hour',metric_nm]].copy()\n",
    "    df['dt_part'] = df['dt_part'].dt.tz_localize(None)\n",
    "    start_dt = pd.to_datetime(scheduler_dict[city_id]['start_dt']).date()\n",
    "    city_schedule = scheduler_dict[city_id]['daily']\n",
    "\n",
    "    df['after_treatment'] = df['dt_part'].dt.date >= start_dt\n",
    "    df['weekend'] = df['weekday'].isin(range(2,6)) | ((df['weekday'] == 6) & (df['hour'] >= 16))\n",
    "\n",
    "    def is_within_schedule(row):\n",
    "        day, hour = row['weekday'], row['hour']\n",
    "        if day not in city_schedule:\n",
    "            return False\n",
    "        for start, end in city_schedule[day]:\n",
    "            if start <= hour <= end:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    df = df[df.apply(is_within_schedule, axis=1)].sort_values('dt_part').reset_index(drop=True)\n",
    "    return df[['dt_part','after_treatment','weekend',metric_nm]].rename(columns={metric_nm:'metric_val'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance(data: pd.DataFrame, weekend: bool):\n",
    "    df = data[data['weekend'] == weekend]\n",
    "    before_treatment = df[~df['after_treatment']]['metric_val'].values\n",
    "    after_treatment = df[df['after_treatment']]['metric_val'].values\n",
    "    \n",
    "    ci = (np.quantile(before_treatment, .025), np.quantile(before_treatment, .975))\n",
    "    p_values = []\n",
    "\n",
    "    for val in after_treatment:\n",
    "        p_values.append(val >= ci[0] and val <= ci[1])\n",
    "\n",
    "    return np.round(ci, 3), np.round(np.mean(p_values), 3), before_treatment, np.round(np.mean(after_treatment), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis (trasport_type = `any`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_dict = get_cities_dict(geo_list)\n",
    "cities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `any` transport type & order type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_metrics_hourly_query = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "main_metrics_hourly_df = utils.read_sql_bq(main_metrics_hourly_query, client=bigquery_client, cache_dir=cache_dir)\n",
    "print(main_metrics_hourly_df.shape)\n",
    "main_metrics_hourly_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_metrics_past_hourly_query = \"\"\"\n",
    ";\"\"\"\n",
    "\n",
    "main_metrics_past_hourly_df = utils.read_sql_bq(main_metrics_past_hourly_query, client=bigquery_client, cache_dir=cache_dir)\n",
    "print(main_metrics_past_hourly_df.shape)\n",
    "main_metrics_past_hourly_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_metrics_daily_to_forecast_query = \"\"\"\n",
    ";\"\"\"\n",
    "\n",
    "main_metrics_daily_to_forecast_df = utils.read_sql_bq(main_metrics_daily_to_forecast_query, client=bigquery_client, cache_dir=cache_dir)\n",
    "print(main_metrics_daily_to_forecast_df.shape)\n",
    "main_metrics_daily_to_forecast_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sc_donors_query = \"\"\"\n",
    ";\"\"\"\n",
    "\n",
    "sc_donors_dict = {row[0]:[int(_) for _ in row[2].split(',')] for row in bigquery_client.query(get_sc_donors_query)}\n",
    "sc_donors_list = list(set(sum(sc_donors_dict.values(), [])))\n",
    "sc_donors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_metrics_daily_to_sc_query = f\"\"\"\n",
    ";\"\"\"\n",
    "\n",
    "main_metrics_daily_to_sc_df = utils.read_sql_bq(main_metrics_daily_to_sc_query, client=bigquery_client, cache_dir=cache_dir)\n",
    "print(main_metrics_daily_to_sc_df.shape)\n",
    "main_metrics_daily_to_sc_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_city = 1234\n",
    "t_city_nm = cities_dict[t_city]['city_name']\n",
    "t_city_nm_title = f'<b> {t_city_nm}</b>'\n",
    "t_start_dt = pd.to_datetime(scheduler_dict[t_city]['start_dt']).date()\n",
    "plot_start_date = datetime(2025,2,5).date()\n",
    "\n",
    "# Current data\n",
    "t_metrics_hourly_df = main_metrics_hourly_df[\n",
    "    (main_metrics_hourly_df['city_id'] == t_city) &\n",
    "    (main_metrics_hourly_df['dt_part'].dt.date >= plot_start_date) &\n",
    "    (main_metrics_past_hourly_df['dt_part'].dt.date < datetime(2026,1,1).date())\n",
    "].sort_values('dt_part').reset_index(drop=True)\n",
    "\n",
    "#YoY data\n",
    "t_past_hourly_df = main_metrics_past_hourly_df[\n",
    "    (main_metrics_past_hourly_df['city_id']==t_city) &\n",
    "    (main_metrics_past_hourly_df['dt_part'].dt.date < datetime(2026,1,1).date())\n",
    "].sort_values('dt_part').reset_index(drop=True)\n",
    "\n",
    "# Forecast\n",
    "start_dt = pd.to_datetime(scheduler_dict[t_city]['start_dt']).date()\n",
    "horizon = (datetime(2026,1,1).date() - start_dt).days\n",
    "\n",
    "# Forecast - autoregression\n",
    "ar_forecast_df = main_metrics_daily_to_forecast_df[\n",
    "    (main_metrics_daily_to_forecast_df['city_id']==t_city)\n",
    "].sort_values('dt_part').drop(columns=['city_id'])\n",
    "\n",
    "ar_forecast_df['dt_part'] = pd.to_datetime(ar_forecast_df['dt_part'])\n",
    "ar_forecast_df = ar_forecast_df.set_index('dt_part').resample('D').sum().astype(float)\n",
    "\n",
    "# Forecast - SC\n",
    "sc_forecast_df = main_metrics_daily_to_sc_df[main_metrics_daily_to_sc_df['city_id'].isin(sc_donors_dict[t_city])]\n",
    "sc_forecast_df['dt_part'] = pd.to_datetime(sc_forecast_df['dt_part'])\n",
    "\n",
    "print('City:\\t\\t', f'{t_city}: {t_city_nm}')\n",
    "print('Start date:\\t',start_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commission revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=f'{t_city_nm_title}: Commission revenue hourly'\n",
    "filename = f'{t_city_nm}: Commission revenue hourly'\n",
    "\n",
    "fig = px.line(\n",
    "    t_metrics_hourly_df,\n",
    "    x='dt_part',\n",
    "    y='commission_revenue_usd',\n",
    "    title=title,\n",
    "    labels={'dt_part': '', 'commission_revenue_usd': ''}\n",
    ")\n",
    "get_vrect(t_city, '2025-03-11', fig, scheduler_dict=scheduler_dict)\n",
    "fig.add_vline(t_start_dt, line_width=1, line_dash='dash', line_color='black') #, annotation_text='start date', annotation_position='top left')\n",
    "\n",
    "fig.update_layout(width=1400, height=500, hovermode='x')\n",
    "\n",
    "fig.show()\n",
    "# fig.write_image(f'{output_path}{filename}.png', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=f'{t_city_nm_title}: Done rate hourly'\n",
    "filename = f'{t_city_nm}: Done rate hourly'\n",
    "\n",
    "fig = px.line(\n",
    "    t_metrics_hourly_df,\n",
    "    x='dt_part', \n",
    "    y='done_rate', \n",
    "    title=title,\n",
    "    labels={'dt_part': '', 'done_rate':''}\n",
    ")\n",
    "get_vrect(t_city, '2025-03-02', fig, scheduler_dict=scheduler_dict)\n",
    "fig.add_vline(t_start_dt, line_width=1, line_dash='dash', line_color='black')\n",
    "\n",
    "fig.update_layout(width=1200, height=500, legend=dict(\n",
    "    orientation='h',\n",
    "    yanchor='bottom',\n",
    "    y=1,\n",
    "    xanchor='left',\n",
    "    x=0\n",
    "), hovermode='x')\n",
    "fig.update_yaxes(tickformat='.0%')\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(f'{output_path}{filename}.png', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YoY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=f'{t_city_nm_title}: Done rate YoY'\n",
    "filename = f'{t_city_nm}: Done rate YoY'\n",
    "\n",
    "fig = px.line(\n",
    "    yoy_ratio(t_past_hourly_df, ['done_rate'], 'rel'),\n",
    "    x='dt_part', \n",
    "    y='done_rate_yoy', \n",
    "    title=title,\n",
    "    labels={'dt_part': '', 'done_rate_yoy':''}\n",
    ")\n",
    "get_vrect(t_city, '2025-03-02', fig, scheduler_dict=scheduler_dict)\n",
    "fig.add_vline(t_start_dt, line_width=1, line_dash='dash', line_color='black')\n",
    "fig.add_hline(0, line_width=1, line_dash='dash', line_color='black')\n",
    "\n",
    "fig.update_layout(width=1200, height=500, legend=dict(\n",
    "    orientation='h',\n",
    "    yanchor='bottom',\n",
    "    y=1,\n",
    "    xanchor='left',\n",
    "    x=0\n",
    "), hovermode='x')\n",
    "fig.update_yaxes(tickformat='.0%')\n",
    "fig.update_xaxes(range=[plot_start_date, datetime(2025,3,2).date()])\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(f'{output_path}{filename}.png', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=f'{t_city_nm_title}: Done rate seasonality'\n",
    "filename = f'{t_city_nm}: Done rate seasonality'\n",
    "\n",
    "fig = px.line(\n",
    "    get_seasonality_data(t_past_hourly_df, ['done_rate'], scale=False),\n",
    "    x='dt_part', \n",
    "    y='done_rate',\n",
    "    color='year', \n",
    "    title=title,\n",
    "    labels={'dt_part': '', 'done_rate':'', 'year':''}\n",
    ")\n",
    "\n",
    "fig.for_each_trace(\n",
    "    lambda trace: trace.update(line=dict(color='blue', width=2.5)) \n",
    "    if trace.name == '2025'\n",
    "    else trace.update(line=dict(color='gray', dash='dot'))\n",
    ")\n",
    "\n",
    "get_vrect(t_city, '2025-03-02', fig, scheduler_dict=scheduler_dict)\n",
    "\n",
    "fig.update_layout(width=1200, height=500, showlegend=False)\n",
    "fig.update_yaxes(tickformat='.0%')\n",
    "fig.update_xaxes(range=[plot_start_date, datetime(2025,3,2).date()])\n",
    "# fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(f'{output_path}{filename}.png', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_metric_nm = 'done_rate'\n",
    "t_sign_df = df_filter_and_markup(data=main_metrics_past_hourly_df, city_id=t_city, scheduler_dict=scheduler_dict, metric_nm=t_metric_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'{t_city_nm}: Done rate distribution (weekday)'\n",
    "\n",
    "t_weekend=False\n",
    "ci, p_value, before_val_array, after_avg_value = get_significance(t_sign_df, weekend=t_weekend)\n",
    "\n",
    "fig, (ax_box, ax_hist) = plt.subplots(\n",
    "    2, 1,\n",
    "    sharex=True,\n",
    "    gridspec_kw={'height_ratios': [1, 4]},\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "\n",
    "sns.boxplot(before_val_array, ax=ax_box, orient='h')\n",
    "ax_box.set(xlabel='', ylabel=None, yticks=[])\n",
    "\n",
    "sns.histplot(before_val_array, kde=False, ax=ax_hist)\n",
    "ax_hist.set(xlabel='Before treatment', ylabel=None, yticks=[])\n",
    "\n",
    "ax_box.axvline(x=after_avg_value, color='black', linestyle='--', linewidth=1)\n",
    "ax_hist.axvline(x=after_avg_value, color='black', linestyle='--', linewidth=1)\n",
    "ax_hist.text(after_avg_value*1.02, ax_hist.get_ylim()[1]*.95, 'After treatment', color='black', fontsize=9, ha='left', va='center', rotation=0)\n",
    "\n",
    "plt.suptitle(title, fontsize=12, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_path}{title}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f'Confidence interval:\\t{ci}')\n",
    "print(f'P-value:\\t\\t{p_value}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rhda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
